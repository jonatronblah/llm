{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20d128c-3165-4aa1-8e84-c7e6a7d01a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.core import set_global_tokenizer\n",
    "from llama_index.core.text_splitter import CodeSplitter\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.packs.code_hierarchy import (\n",
    "    CodeHierarchyAgentPack,\n",
    "    CodeHierarchyNodeParser,\n",
    ")\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg \n",
    "from llama_index.core import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c611779e-d2b6-49d9-99b8-5da8b2c8d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"/setup/on.env\")\n",
    "pg_user = os.getenv(\"POSTGRES_USER\")\n",
    "pg_db = os.getenv(\"POSTGRES_DB\")\n",
    "pg_pwd = os.getenv(\"POSTGRES_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffb32d9-8777-4f89-b8a1-00b09bbba951",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-14B-Instruct\")\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = \"BAAI/bge-base-en-v1.5\"\n",
    ")\n",
    "\n",
    "set_global_tokenizer(tokenizer.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02edc31d-e579-4ad8-a3e2-ae2e7cb590c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(name):\n",
    "    with psycopg.connect(\n",
    "        f\"host=postgres dbname={pg_db} user={pg_user} password={pg_pwd}\"\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                drop table if exists {name};\n",
    "                \"\"\")\n",
    "            conn.commit()\n",
    "\n",
    "\n",
    "drop(\"data_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ff3eac-67e0-4ca5-8e0e-e3c99341750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVectorStore.from_params(\n",
    "    database=pg_db,\n",
    "    host=\"postgres\",\n",
    "    password=pg_pwd,\n",
    "    port=5432,\n",
    "    user=pg_user,\n",
    "    table_name=\"code\",\n",
    "    embed_dim=768,\n",
    "    hnsw_kwargs={\n",
    "        \"hnsw_m\": 14,\n",
    "        \"hnsw_ef_construction\": 72,\n",
    "        \"hnsw_ef_search\": 52,\n",
    "        \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "    },\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28fea25b-34c5-440e-b274-24da0e473acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a008a6156dc48aa84ca44786fc98ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222e70d86a03437fa5aee32b778ff641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330d995227184b1e9d5c8a5e403a0403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_ext = {\"python\": [\".py\"], \"lua\": [\".lua\"], \"c\": [\".c\", \".h\"]}\n",
    "\n",
    "indexes = {}\n",
    "for i in language_ext:\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_dir=\"/notebooks/data/crow-repository/\",\n",
    "        recursive=True,\n",
    "        required_exts=language_ext[i],\n",
    "        file_metadata=lambda x: {\"filepath\": x},\n",
    "    ).load_data()\n",
    "    split_nodes = CodeSplitter(\n",
    "            language=i, max_chars=1024, chunk_lines=20\n",
    "        ).get_nodes_from_documents(documents)\n",
    "    index = VectorStoreIndex(split_nodes, storage_context=storage_context, \n",
    "                             show_progress=True, embed_model=Settings.embed_model,\n",
    "                            transformations=[CodeSplitter(language=i, max_chars=1024, chunk_lines=20)])\n",
    "    indexes.update({i: index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f2f828-f5da-42d5-baea-7cb9ec9bc1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7fd7146408f0>,\n",
       " <llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7fd889be4ef0>,\n",
       " <llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7fd6f458f8f0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indexes[i] for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e56d68-8269-4a7b-9be2-cbb738f12c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4060 Ti, compute capability 8.9, VMM: yes\n",
      "llama_load_model_from_file: using device CUDA0 (NVIDIA GeForce RTX 4060 Ti) - 14287 MiB free\n",
      "llama_model_loader: loaded meta data with 38 key-value pairs and 579 tensors from /llamaindex_cache/models/Qwen2.5-Coder-14B-Instruct-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 Coder 14B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5-Coder\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 14B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/Qwen/Qwen2.5-C...\n",
      "llama_model_loader: - kv   8:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   9:                  general.base_model.0.name str              = Qwen2.5 Coder 14B\n",
      "llama_model_loader: - kv  10:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  11:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-C...\n",
      "llama_model_loader: - kv  12:                               general.tags arr[str,6]       = [\"code\", \"codeqwen\", \"chat\", \"qwen\", ...\n",
      "llama_model_loader: - kv  13:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  14:                          qwen2.block_count u32              = 48\n",
      "llama_model_loader: - kv  15:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  16:                     qwen2.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv  17:                  qwen2.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv  18:                 qwen2.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv  19:              qwen2.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  20:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  21:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  22:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  34:                      quantize.imatrix.file str              = /models_out/Qwen2.5-Coder-14B-Instruc...\n",
      "llama_model_loader: - kv  35:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  36:             quantize.imatrix.entries_count i32              = 336\n",
      "llama_model_loader: - kv  37:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  241 tensors\n",
      "llama_model_loader: - type q6_K:  338 tensors\n",
      "llm_load_vocab: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 22\n",
      "llm_load_vocab: token to piece cache size = 0.9310 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 152064\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 5\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 14B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 14.77 B\n",
      "llm_load_print_meta: model size       = 11.29 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen2.5 Coder 14B Instruct\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 'ÄĬ'\n",
      "llm_load_print_meta: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "llm_load_print_meta: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "llm_load_print_meta: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "llm_load_print_meta: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: FIM REP token    = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: EOG token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOG token        = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 48 repeating layers to GPU\n",
      "llm_load_tensors: offloading output layer to GPU\n",
      "llm_load_tensors: offloaded 49/49 layers to GPU\n",
      "llm_load_tensors:        CUDA0 model buffer size = 10948.23 MiB\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   609.08 MiB\n",
      "...........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 12384\n",
      "llama_new_context_with_model: n_ctx_per_seq = 12384\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (12384) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  2322.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2322.00 MiB, K (f16): 1161.00 MiB, V (f16): 1161.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.58 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =  1031.69 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    34.19 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1686\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.chunks_count': '128', 'quantize.imatrix.entries_count': '336', 'quantize.imatrix.file': '/models_out/Qwen2.5-Coder-14B-Instruct-GGUF/Qwen2.5-Coder-14B-Instruct.imatrix', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-Coder-14B', 'general.license': 'apache-2.0', 'qwen2.attention.head_count_kv': '8', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'general.type': 'model', 'qwen2.block_count': '48', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.base_model.0.name': 'Qwen2.5 Coder 14B', 'general.license.link': 'https://huggingface.co/Qwen/Qwen2.5-Coder-14B-Instruct/blob/main/LICENSE', 'tokenizer.ggml.pre': 'qwen2', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Qwen', 'general.size_label': '14B', 'tokenizer.ggml.add_bos_token': 'false', 'general.basename': 'Qwen2.5-Coder', 'qwen2.embedding_length': '5120', 'tokenizer.ggml.padding_token_id': '151643', 'general.architecture': 'qwen2', 'qwen2.context_length': '32768', 'qwen2.feed_forward_length': '13824', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'qwen2.attention.head_count': '40', 'qwen2.rope.freq_base': '1000000.000000', 'tokenizer.ggml.eos_token_id': '151645', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'general.finetune': 'Instruct', 'general.file_type': '18', 'general.name': 'Qwen2.5 Coder 14B Instruct', 'tokenizer.ggml.bos_token_id': '151643'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "def completion_to_prompt(completion):\n",
    "   return f\"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n{completion}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"<|im_start|>system\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|im_start|>user\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|im_start|>assistant\\n{message.content}<|im_end|>\\n\"\n",
    "\n",
    "    if not prompt.startswith(\"<|im_start|>system\"):\n",
    "        prompt = \"<|im_start|>system\\n\" + prompt\n",
    "        \n",
    "\n",
    "    prompt = prompt + '<|im_start|>\"You are Qwen, created by Alibaba Cloud. You are a helpful assistant. You answer user queries about the crow software library using retreived source code data from the library repository.\\n'\n",
    "\n",
    "    return prompt\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_url=\"https://huggingface.co/bartowski/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q6_K.gguf\",\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=1024,\n",
    "    context_window=12384,\n",
    "    generate_kwargs={\"repeat_penalty\": 1.15, \"top_k\": 0, \"top_p\": 0.5, \"min_p\": 0.1},\n",
    "    model_kwargs={\n",
    "        \"n_gpu_layers\": -1,\n",
    "    },\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "badd77e9-2bbe-47c4-8a11-8e693874abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [indexes[i].as_retriever() for i in indexes],\n",
    "    similarity_top_k=2,\n",
    "    num_queries=4,\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    ")\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6327173c-191a-4cff-8ca1-12fed461b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 81 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     657.18 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2697.47 ms /    40 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated queries:\n",
      "1. How to use lua ASL library for melody generation\n",
      "2. Example of generating a melody using the lua ASL library\n",
      "3. Lua ASL library tutorial: Melody creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 8 prefix-match hit, remaining 800 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     657.18 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   800 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   401 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   26424.08 ms /  1201 tokens\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Using the provided context, answer the following query: How can I use the lua ASL library to generate a melody? Can you provide an example?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198ee367-deb9-4a89-a9b9-43c8d67d7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To generate a melody using the lua ASL library, you can use functions like `note`, `lfo`, `oscillate`, and `pulse`. Here's an example of how to create a simple melody:\n",
      "\n",
      "```lua\n",
      "-- Define the notes for the melody\n",
      "local melody_notes = {60, 62, 64, 65, 67, 69}\n",
      "\n",
      "-- Create a sequence of notes with durations\n",
      "local melody_sequence = {}\n",
      "for _, note in ipairs(melody_notes) do\n",
      "    table.insert(melody_sequence, note(1/8)) -- Play each note for an eighth beat\n",
      "end\n",
      "\n",
      "-- Combine the notes into a single ASL descriptor\n",
      "local melody_descriptor = asl.sequence(unpack(melody_sequence))\n",
      "\n",
      "-- Apply an LFO to modulate the pitch of the melody\n",
      "local lfo_descriptor = lfo(2, 10, 'sine') -- Create an LFO with a frequency of 2 Hz and amplitude of 10\n",
      "\n",
      "-- Combine the melody descriptor with the LFO descriptor\n",
      "local final_melody_descriptor = asl.multiply(melody_descriptor, lfo_descriptor)\n",
      "\n",
      "-- Play the final melody on output 1\n",
      "output[1](final_melody_descriptor)\n",
      "```\n",
      "\n",
      "In this example, we first define a sequence of notes for our melody. We then create an ASL descriptor for each note with a duration of one eighth beat using the `note` function and combine them into a single sequence using `asl.sequence`. Next, we create an LFO to modulate the pitch of the melody using the `lfo` function. Finally, we multiply the melody descriptor by the LFO descriptor using `asl.multiply` to apply the modulation, and play the resulting melody on output 1.\n",
      "\n",
      "Please note that this is a simplified example and you may need to adjust parameters such as note durations, frequencies, amplitudes, etc., depending on your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
